wish list/ requirements
=======================

 * good visualizations (show boxes, and show peeling trajectory)
 * box init should be based on uncertainty limits, thus model interface is
   a argument for prim
 * try to use pandas internally, paving the way for moving to pandas in the 
   future
 * investigate multiple classes by using e.g. gini impurity in obj function
 * much clearer error handling in case of no box being found, or, in case of 
   using a classify, the number of cases of interest is either very large 
   or small. 
 * create possibility to have f-prim, where a weight parameter allows
   one to make tradeoffs in coverage and density
   
objective function
------------------

The various ideas for the objective function raises the question what
data is needed in the objective function for each of these cases. Clearly,
the current implementation which only uses y_new and y_old is not enough.
But what should we use instead?

 * for coverage and density calculations, you need y_init as well.
 * for gini and information gain, see python machine learning algorithmic
   perspective book
   
PRIM implementation detail
--------------------------

Now we copy a lot of data, is it not possible to use indices instead. So, you 
peel and paste by removing or adding indices back in. This can be achieved 
quite easily by replacing logical with where. 

The question is how pandas and indices relate. 